{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup and Pre-processing\n",
    "\n",
    "Before we can analyze the data we need to clean the raw data and bring it to a format suited for the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Basic imports and setup.\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "from neuropsymodelcomparison.dataprocessing import analysis\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in raw data from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/\")\n",
    "raw_data_path = data_path / 'raw/'\n",
    "\n",
    "users = pd.read_csv(raw_data_path / 'users.csv')\n",
    "blocks = pd.read_csv(raw_data_path / 'blocks.csv', index_col='id')\n",
    "blocks['time_iso'] = pd.to_datetime(blocks['time_iso'])\n",
    "trials = pd.read_csv(raw_data_path / 'trials.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection began on August 1st 2020 and ended on August 31st 2020. Data collected before that time period was pilot data to test the funtionality of the app and tune the priors.  \n",
    "Filter out invalid data. Keep a record of what was excluded and for which reasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '2020-08-01'\n",
    "end_date = '2020-09-01'  # At the beginning of the day at 00:00:00, so at the end of the previous day.\n",
    "\n",
    "# How many testers were there?\n",
    "n_testers = blocks.loc[blocks['time_iso'] < start_date, 'user_id'].nunique()\n",
    "# We're only interested in first time participations.\n",
    "blocks = blocks.loc[blocks['nth_session'] == 1, :]\n",
    "# Keep only blocks within data collection time period.\n",
    "blocks = blocks.loc[(blocks['time_iso'] > start_date) & (blocks['time_iso'] < end_date), :]\n",
    "# How many people took part during that period?\n",
    "n_users = blocks['user_id'].nunique()\n",
    "\n",
    "# If a subsequent block is completed within 2 seconds after the previous one, there was a malfunction in the app. A session must consist of 3 blocks.\n",
    "blocks, n_errors, invalid_sessions = analysis.remove_erroneous_blocks(blocks, delta_time=2.0, n_blocks=3)\n",
    "n_users_malfunction = n_users - blocks['user_id'].nunique()\n",
    "# Merge data to 1 table.\n",
    "df = analysis.join_data(users, blocks, trials)\n",
    "# Remove trials where sliders where not grabbed concurrently or grabbed at all.\n",
    "df, n_trials_removed = analysis.get_valid_trials(df)\n",
    "# Further remove trials for which sliders where grabbed with too much time apart.\n",
    "# The arbitrary choice for a threshold is set to a third of the available time.\n",
    "n_trials = len(df)\n",
    "df = df.loc[df['grab_diff'] < (blocks['trial_duration'].median()/3), :]\n",
    "n_trials_removed += n_trials - len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save intermediate data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:root:Written interim trials data to /home/olaf/code/NeuroPsyResearchAnalysis/data/interim/trials.csv\nINFO:root:Written sampling data to /home/olaf/code/NeuroPsyResearchAnalysis/data/interim/sampling.txt\n"
    }
   ],
   "source": [
    "interim_data_path = data_path / 'interim'\n",
    "# Save trial data.\n",
    "file_path = interim_data_path / 'trials.csv'\n",
    "df.to_csv(file_path)\n",
    "logging.info(f\"Written interim trials data to {file_path.resolve()}\")\n",
    "\n",
    "# Save data about exclusions.\n",
    "sampling_path = interim_data_path / 'sampling.txt'\n",
    "with sampling_path.open(mode='w') as f:\n",
    "    f.write(f\"start_date={start_date}\\n\")\n",
    "    f.write(f\"end_date={str((pd.to_datetime(end_date) - pd.to_timedelta(1, unit='d')).date())}\\n\")\n",
    "    f.write(f\"n_testers={n_testers}\\n\")\n",
    "    f.write(f\"n_users={n_users}\\n\")\n",
    "    f.write(f\"n_excluded_malfunction={n_users_malfunction}\\n\")\n",
    "    f.write(f\"n_invalid_sessions={len(invalid_sessions)}\\n\")\n",
    "    f.write(f\"n_invalid_trials={n_trials_removed}\\n\")\n",
    "logging.info(f\"Written sampling data to {sampling_path.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pm3': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598195518574"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}